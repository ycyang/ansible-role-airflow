---

# Defaults vars file for airflow role

# Installation vars
airflow_user_name: 'airflow'
airflow_user_group: "{{ airflow_user_name }}"
airflow_user_shell: '/bin/false'
airflow_user_home_path: '/var/lib/airflow'
airflow_user_home_mode: '0700'

airflow_log_path: '/var/log/airflow'
airflow_log_owner: "{{ airflow_user_name }}"
airflow_log_group: "{{ airflow_user_group }}"
airflow_log_mode: '0700'

airflow_pid_path: '/var/run/airflow'
airflow_pid_owner: "{{ airflow_user_name }}"
airflow_pid_group: "{{ airflow_user_group }}"
airflow_pid_mode: '0700'

airflow_virtualenv: "{{ airflow_user_home_path }}/venv"
airflow_python_version: 'python3.4'
airflow_packages:
  - name: 'Cython'
    version: '0.24'
  - name: 'airflow'
    version: '1.7.1.3'
  - name: 'setuptools'
    version: '23.0.0'
airflow_extra_packages:
  - name: 'airflow[crypto]'
airflow_system_dependencies: []

# Services management
airflow_managed_upstart_services: []
airflow_managed_initd_services:
  - 'airflow-scheduler'
  - 'airflow-webserver'

airflow_services_states:
  - name: 'airflow-webserver'
    enabled: True
    state: 'started'
  - name: 'airflow-scheduler'
    enabled: True
    state: 'started'


# Webserver service configuration
airflow_webserver_port: 8080
airflow_webserver_workers: 1
airflow_webserver_worker_class: 'sync'
airflow_webserver_worker_timeout: 30
airflow_webserver_hostname: "{{ ansible_default_ipv4.address }}"
airflow_webserver_pid_file: "{{ airflow_pid_path }}/airflow-webserver.pid"
airflow_webserver_log_file: "{{ airflow_log_path }}/airflow-webserver.log"
airflow_webserver_debug: False
airflow_webserver_respawn_limit_count: 5
airflow_webserver_respawn_limit_timeperiod: 30

# Scheduler service configuration
airflow_scheduler_runs: 0
airflow_scheduler_pid_file: "{{ airflow_pid_path }}/airflow-scheduler.pid"
airflow_scheduler_log_file: "{{ airflow_log_path }}/airflow-scheduler.log"
airflow_scheduler_respawn_limit_count: 5
airflow_scheduler_respawn_limit_timeperiod: 30

# Databases variables
airflow_manage_database: True
airflow_database_engine: 'mysql'

# Set do_init to false if database already initialized
airflow_do_init_db: True
airflow_do_upgrade_db: True

# Default configuration
airflow_defaults_config:
  core:
    home: "{{ airflow_user_home_path }}"
    dags_folder: "{{ airflow_user_home_path }}/dags"
    base_log_folder: "{{ airflow_user_home_path }}/logs"
    remote_base_log_folder: ''
    remote_log_conn_id: ''
    encrypt_s3_logs: False
    s3_log_folder: ''
    executor: 'SequentialExecutor'
    sql_alchemy_conn: "sqlite:///{{ airflow_user_home_path }}/airflow.db"
    sql_alchemy_pool_size: 5
    sql_alchemy_pool_recycle: 3600
    parallelism: 32
    dag_concurrency: 16
    dags_are_paused_at_creation: True
    non_pooled_task_slot_count: 128
    max_active_runs_per_dag: 16
    load_examples: False
    plugins_folder: "{{ airflow_user_home_path }}/plugins"
    fernet_key: 'cryptography_not_found_storing_passwords_in_plain_text'
    donot_pickle: False
    dagbag_import_timeout: 30
    task_runner: 'BashTaskRunner'
    default_impersonation: ''
    security: ''
    unit_test_mode: False

  cli:
    api_client: 'airflow.api.client.local_client'
    endpoint_url: 'http://localhost:8080'

  api:
    auth_backend: 'airflow.api.auth.backend.default'

  operators:
    default_owner: 'Airflow'
    default_cpus: 1
    default_ram: 512
    default_disk: 512
    default_gpus: 0

  webserver:
    base_url: 'http://localhost:8080'
    web_server_host: '0.0.0.0'
    web_server_port: 8080
    web_server_ssl_cert: ''
    web_server_ssl_key: ''
    web_server_worker_timeout: 120
    worker_refresh_batch_size: 1
    worker_refresh_interval: 30
    secret_key: 'temporary_key'
    workers: 4
    worker_class: 'sync'
    access_logfile: '-'
    error_logfile: '-'
    expose_config: True
    authenticate: False
    filter_by_owner: False
    owner_mode: 'user'
    dag_orientation: 'LR'
    demo_mode: False
    log_fetch_timeout_sec: 5
    hide_paused_dags_by_default: False

  email:
    email_backend: 'airflow.utils.email.send_email_smtp'

  smtp:
    smtp_host: 'localhost'
    smtp_starttls: True
    smtp_ssl: False
    smtp_port: 25
    smtp_mail_from: 'airflow@airflow.com'

  celery:
    celery_app_name: 'airflow.executors.celery_executor'
    celeryd_concurrency: 16
    worker_log_server_port: 8793
    broker_url: 'sqla+mysql://airflow:airflow@localhost:3306/airflow'
    celery_result_backend: 'db+mysql://airflow:airflow@localhost:3306/airflow'
    flower_host: '0.0.0.0'
    flower_port: 5555
    default_queue: 'default'

  scheduler:
    job_heartbeat_sec: 5
    scheduler_heartbeat_sec: 5
    run_duration: -1
    min_file_process_interval: 0
    dag_dir_list_interval: 300
    print_stats_interval: 30
    child_process_log_directory: "{{ airflow_user_home_path }}/logs/scheduler"
    scheduler_zombie_task_threshold: 300
    catchup_by_default: True
    statsd_on: False
    statsd_host: 'localhost'
    statsd_port: 8125
    statsd_prefix: 'airflow'
    max_threads: 2
    authenticate: False

  mesos:
    master: 'localhost:5050'
    framework_name: 'Airflow'
    task_cpu: 1
    task_memory: 256
    checkpoint: False
    authenticate: False

  kerberos:
    ccache: '/tmp/airflow_krb5_ccache'
    principal: 'airflow'
    reinit_frequency: 3600
    kinit_path: 'kinit'
    keytab: 'airflow.keytab'

  github_enterprise:
    api_rev: 'v3'

  admin:
    hide_sensitive_variable_fields: True


airflow_user_config: {}
airflow_config: "{{ airflow_defaults_config | combine(airflow_user_config, recursive=True) }}"

# Logrotate configuration
airflow_logrotate_config:
  - filename: '/etc/logrotate.d/airflow'
    log_pattern:
      - "{{ airflow_log_path }}/*.log"
    options:
      - 'rotate 12'
      - 'weekly'
      - 'compress'
      - 'delaycompress'
      - "create 640 {{ airflow_log_owner }} {{ airflow_log_group }}"
      - 'postrotate'
      - 'endscript'
